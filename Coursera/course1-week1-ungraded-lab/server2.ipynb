{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0d7a185c7189272243b4823288e938adbf8a9c14fac77efacc5e58c48a0cfe526",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import numpy as np\n",
    "import io\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "from enum import Enum\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import StreamingResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = tv.transforms.Compose([\n",
    "                tv.transforms.Resize((512,512)),\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[1, 1, 1]),\n",
    "            ])\n",
    "\n",
    "unload = tv.transforms.Compose([\n",
    "                tv.transforms.Normalize(mean=[-0.485,-0.456,-0.406],\n",
    "                                    std=[1,1,1]),                \n",
    "                tv.transforms.Lambda(lambda x: x.clamp(0,1))\n",
    "            ])\n",
    "to_image = tv.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(image_name):\n",
    "    \n",
    "    # load the image from the notebook filesystem\n",
    "    image = Image.open(image_name)\n",
    "\n",
    "    return to_tensor(image).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_name = \"images_uploaded\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"Style Transfer Pro\")\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return \"Working like a charm! Go to http://localhost:8000/docs to test!\"\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def prediction(input_img: UploadFile = File(...), style: UploadFile = File(...)):\n",
    "    filename = input_img.filename\n",
    "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
    "    if not fileExtension:\n",
    "        raise HTTPException(status_code=415, detail=\"Unsupported file provided\")\n",
    "\n",
    "    input_image = image_loader(io.BytesIO(input_img.file.read()))\n",
    "    style_image = image_loader(io.BytesIO(style.file.read()))\n",
    "\n",
    "    def get_features(module, x, y):\n",
    "    #     print('here')\n",
    "        features.append(y)\n",
    "        \n",
    "    def gram_matrix(x):\n",
    "        \n",
    "        b, c, h, w = x.size()\n",
    "        F = x.view(b,c,h*w)\n",
    "        G = torch.bmm(F, F.transpose(1,2))/(h*w)\n",
    "        return G\n",
    "\n",
    "    VGG = tv.models.vgg19(pretrained=True).features\n",
    "    VGG.cuda()\n",
    "\n",
    "    for i, layer in enumerate(VGG):\n",
    "        \n",
    "        if i in [0,5,10,19,21,28]:\n",
    "            VGG[i].register_forward_hook(get_features)\n",
    "        \n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            VGG[i] = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "    VGG.eval()\n",
    "\n",
    "    for p in VGG.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    features = []\n",
    "    VGG(input_image.unsqueeze(0))\n",
    "    c_target = features[4].detach()\n",
    "\n",
    "    features = []\n",
    "    VGG(style_image.unsqueeze(0))\n",
    "    f_targets = features[:4]+features[5:]\n",
    "    gram_targets = [gram_matrix(i).detach() for i in f_targets]\n",
    "\n",
    "    alpha = 1\n",
    "    beta = 1e3\n",
    "    iterations = 100\n",
    "    image = input_image.clone().unsqueeze(0)\n",
    "    # image = torch.randn(1,3,512,512).cuda()\n",
    "    images = []\n",
    "    optimizer = optim.LBFGS([\n",
    "    image.requires_grad_()], lr=1)    \n",
    "    mse_loss = nn.MSELoss(reduction='mean')\n",
    "    l_c = []\n",
    "    l_s = []\n",
    "    counter = 0\n",
    "\n",
    "    for itr in range(iterations):\n",
    "\n",
    "        features = []\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            VGG(image)\n",
    "            t_features = features[-6:]\n",
    "            content = t_features[4]\n",
    "            style_features = t_features[:4]+t_features[5:]\n",
    "            t_features = []\n",
    "            gram_styles = [gram_matrix(i) for i in style_features]\n",
    "            c_loss = alpha * mse_loss(content, c_target)\n",
    "            s_loss = 0\n",
    "\n",
    "            for i in range(5):\n",
    "                n_c = gram_styles[i].shape[0]\n",
    "                s_loss += beta * mse_loss(gram_styles[i],gram_targets[i])/(n_c**2)\n",
    "\n",
    "            total_loss = c_loss+s_loss\n",
    "\n",
    "            l_c.append(c_loss)\n",
    "            l_s.append(s_loss)\n",
    "            \n",
    "            total_loss.backward()\n",
    "            return total_loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        \n",
    "\n",
    "        if itr%1 == 0:\n",
    "            temp = unload(image[0].cpu().detach())\n",
    "            temp = to_image(temp)\n",
    "            temp = np.array(temp)\n",
    "            images.append(temp)\n",
    "            imageio.mimsave(f'styled_images/{filename.split(\".\")[0]}progress.gif', images)\n",
    "\n",
    "    output_image = images[-1]\n",
    "    plt.imsave(f\"styled_images/{filename}\", output_image)\n",
    "\n",
    "    file_image = open(f'styled_images/{filename}', mode='rb')\n",
    "\n",
    "    return StreamingResponse(file_image, media_type=\"image/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:     Started server process [12020]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "INFO:     127.0.0.1:53350 - \"POST /predict HTTP/1.1\" 500 Internal Server Error\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 396, in run_asgi\n",
      "    result = await app(self.scope, self.receive, self.send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 45, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastapi\\applications.py\", line 199, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 181, in __call__\n",
      "    raise exc from None\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 159, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\exceptions.py\", line 82, in __call__\n",
      "    raise exc from None\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\exceptions.py\", line 71, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\routing.py\", line 580, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\routing.py\", line 241, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\routing.py\", line 52, in app\n",
      "    response = await func(request)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastapi\\routing.py\", line 201, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastapi\\routing.py\", line 150, in run_endpoint_function\n",
      "    return await run_in_threadpool(dependant.call, **values)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\starlette\\concurrency.py\", line 40, in run_in_threadpool\n",
      "    return await loop.run_in_executor(None, func, *args)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\futures.py\", line 260, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\futures.py\", line 178, in result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\thread.py\", line 57, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-6-bcf8e20e1bcf>\", line 49, in prediction\n",
      "    VGG(style_img.unsqueeze(0))\n",
      "NameError: name 'style_img' is not defined\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
    "\n",
    "uvicorn.run(app, host=host, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}